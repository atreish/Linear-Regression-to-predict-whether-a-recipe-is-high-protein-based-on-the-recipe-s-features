{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import scipy.stats\n",
    "import scipy.optimize as so\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>advance prep required</th>\n",
       "      <th>alabama</th>\n",
       "      <th>alaska</th>\n",
       "      <th>alcoholic</th>\n",
       "      <th>almond</th>\n",
       "      <th>amaretto</th>\n",
       "      <th>anchovy</th>\n",
       "      <th>...</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rhubarb Roulade</td>\n",
       "      <td>256.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caramel Macadamia Nut Crunch</td>\n",
       "      <td>223.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Marnier Brownie Kisses</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herb Salad Spring Rolls with Spicy Peanut Sauce</td>\n",
       "      <td>224.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Festival</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 673 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  calories  protein  \\\n",
       "0                                  Rhubarb Roulade      256.0      6.0   \n",
       "1                     Caramel Macadamia Nut Crunch      223.0      2.0   \n",
       "2                     Grand Marnier Brownie Kisses      195.0      2.0   \n",
       "3  Herb Salad Spring Rolls with Spicy Peanut Sauce      224.0      8.0   \n",
       "4                                         Festival      219.0      0.0   \n",
       "\n",
       "   advance prep required  alabama  alaska  alcoholic  almond  amaretto  \\\n",
       "0                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "1                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "2                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "3                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "4                    0.0      0.0     0.0        1.0     0.0       0.0   \n",
       "\n",
       "   anchovy  ...  yogurt  yonkers  yuca  zucchini  cookbooks  leftovers  snack  \\\n",
       "0      0.0  ...     0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
       "1      0.0  ...     0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
       "2      0.0  ...     0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
       "3      0.0  ...     0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
       "4      0.0  ...     0.0      0.0   0.0       0.0        0.0        0.0    0.0   \n",
       "\n",
       "   snack week  turkey  label  \n",
       "0         0.0     0.0      0  \n",
       "1         0.0     0.0      0  \n",
       "2         0.0     0.0      0  \n",
       "3         0.0     0.0      0  \n",
       "4         0.0     0.0      0  \n",
       "\n",
       "[5 rows x 673 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upload Data and assign Index as first column and add Binary 1/0 for Final Column as 'label'\n",
    "\n",
    "df_recipe = pd.read_csv('final_data_set.csv',index_col=0)\n",
    "df_recipe['label']=df_recipe['protein']/df_recipe['calories']\n",
    "df_recipe['label'] = np.where(df_recipe['label']>0.1, 1, 0)\n",
    "df_recipe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10061\n",
       "1      532\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of each class label\n",
    "\n",
    "df_recipe.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'calories', 'protein', 'advance prep required', 'alabama',\n",
       "       'alaska', 'alcoholic', 'almond', 'amaretto', 'anchovy',\n",
       "       ...\n",
       "       'yogurt', 'yonkers', 'yuca', 'zucchini', 'cookbooks', 'leftovers',\n",
       "       'snack', 'snack week', 'turkey', 'label'],\n",
       "      dtype='object', length=673)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index of columns and length \n",
    "\n",
    "df_recipe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many columns include any null values?\n",
    "\n",
    "null_columns = df_recipe.columns[df_recipe.isnull().any()]\n",
    "df_recipe[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                     object\n",
       "calories                 float64\n",
       "protein                  float64\n",
       "advance prep required    float64\n",
       "alabama                  float64\n",
       "                          ...   \n",
       "leftovers                float64\n",
       "snack                    float64\n",
       "snack week               float64\n",
       "turkey                   float64\n",
       "label                      int32\n",
       "Length: 673, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the different data types?\n",
    "\n",
    "df_recipe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace any special characters with underscore (_)\n",
    "\n",
    "df_recipe.columns = df_recipe.columns.str.replace('[^a-zA-Z0-9]', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advance_prep_required</th>\n",
       "      <th>alabama</th>\n",
       "      <th>alaska</th>\n",
       "      <th>alcoholic</th>\n",
       "      <th>almond</th>\n",
       "      <th>amaretto</th>\n",
       "      <th>anchovy</th>\n",
       "      <th>anise</th>\n",
       "      <th>anniversary</th>\n",
       "      <th>anthony_bourdain</th>\n",
       "      <th>...</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack_week</th>\n",
       "      <th>turkey</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   advance_prep_required  alabama  alaska  alcoholic  almond  amaretto  \\\n",
       "0                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "1                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "2                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "3                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "4                    0.0      0.0     0.0        1.0     0.0       0.0   \n",
       "\n",
       "   anchovy  anise  anniversary  anthony_bourdain  ...  yogurt  yonkers  yuca  \\\n",
       "0      0.0    0.0          0.0               0.0  ...     0.0      0.0   0.0   \n",
       "1      0.0    0.0          0.0               0.0  ...     0.0      0.0   0.0   \n",
       "2      0.0    0.0          0.0               0.0  ...     0.0      0.0   0.0   \n",
       "3      0.0    0.0          0.0               0.0  ...     0.0      0.0   0.0   \n",
       "4      0.0    0.0          0.0               0.0  ...     0.0      0.0   0.0   \n",
       "\n",
       "   zucchini  cookbooks  leftovers  snack  snack_week  turkey  label  \n",
       "0       0.0        0.0        0.0    0.0         0.0     0.0      0  \n",
       "1       0.0        0.0        0.0    0.0         0.0     0.0      0  \n",
       "2       0.0        0.0        0.0    0.0         0.0     0.0      0  \n",
       "3       0.0        0.0        0.0    0.0         0.0     0.0      0  \n",
       "4       0.0        0.0        0.0    0.0         0.0     0.0      0  \n",
       "\n",
       "[5 rows x 670 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we will restrict of data to all recipes and the Label. Remove Title, Calories, and Protein\n",
    "\n",
    "data = df_recipe.iloc[:,3:].copy()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advance_prep_required</th>\n",
       "      <th>alabama</th>\n",
       "      <th>alaska</th>\n",
       "      <th>alcoholic</th>\n",
       "      <th>almond</th>\n",
       "      <th>amaretto</th>\n",
       "      <th>anchovy</th>\n",
       "      <th>anise</th>\n",
       "      <th>anniversary</th>\n",
       "      <th>anthony_bourdain</th>\n",
       "      <th>...</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack_week</th>\n",
       "      <th>turkey</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       advance_prep_required  alabama  alaska  alcoholic  almond  amaretto  \\\n",
       "20117                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "20118                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "20119                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "20120                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "20121                    0.0      0.0     0.0        0.0     0.0       0.0   \n",
       "\n",
       "       anchovy  anise  anniversary  anthony_bourdain  ...    yogurt  yonkers  \\\n",
       "20117      0.0    0.0          0.0               0.0  ...  0.179044      0.0   \n",
       "20118      0.0    0.0          0.0               0.0  ...  0.000000      0.0   \n",
       "20119      0.0    0.0          0.0               0.0  ...  0.000000      0.0   \n",
       "20120      0.0    0.0          0.0               0.0  ...  0.000000      0.0   \n",
       "20121      0.0    0.0          0.0               0.0  ...  0.000000      0.0   \n",
       "\n",
       "       yuca  zucchini  cookbooks  leftovers  snack  snack_week    turkey  \\\n",
       "20117   0.0       0.0        0.0        0.0    0.0         0.0  0.820956   \n",
       "20118   0.0       0.0        0.0        0.0    0.0         0.0  0.000000   \n",
       "20119   0.0       0.0        0.0        0.0    0.0         0.0  1.000000   \n",
       "20120   0.0       0.0        0.0        0.0    0.0         0.0  0.000000   \n",
       "20121   0.0       0.0        0.0        0.0    0.0         0.0  0.000000   \n",
       "\n",
       "       label  \n",
       "20117      1  \n",
       "20118      1  \n",
       "20119      1  \n",
       "20120      1  \n",
       "20121      1  \n",
       "\n",
       "[5 rows x 670 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance the dataset using the SMOTE() function to even the \n",
    "\n",
    "oversample = SMOTE(random_state=0)\n",
    "X, y = oversample.fit_resample(data.iloc[:,:-1], data.iloc[:,-1])\n",
    "data_balance = pd.concat([X, y],axis=1)\n",
    "data_balance.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10061\n",
       "1    10061\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balance.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we define a predict function that will try to predict whether an object is class 1 or 0 based on\n",
    "our sigmoid transform. We will use an input Beta that will act as coefficients to our vector elements and \n",
    "then using different threshold to tune the best threshold we will predict the class\"\"\"\n",
    "\n",
    "def predict(df, Beta, threshold):\n",
    "    pred_linear = np.dot(np.array(df), Beta)\n",
    "    # using sigmoid tranform to logistic\n",
    "    predictions = 1 / (1 + np.exp(-pred_linear))\n",
    "    predictions = np.where(predictions > threshold, 1, 0)\n",
    "    return predictions\n",
    "\n",
    "def std_revenue(revenues_list):\n",
    "    # Standard deviation of revenues list\n",
    "    # Using sum() + list comprehension\n",
    "    mean = sum(revenues_list) / len(revenues_list)\n",
    "    variance = sum([((x - mean) ** 2) for x in revenues_list]) / (len(revenues_list)-1)\n",
    "    res = variance ** 0.5\n",
    "    std_error_revenue = np.round(res/(len(revenues_list)),2)\n",
    "    return std_error_revenue\n",
    "\n",
    "\"\"\"Using hp_predictions_and_actuals as an imput parameter the following function is given so that \n",
    "we can calculate Revenue\"\"\"\n",
    "\n",
    "def simulate(hp_predictions_and_actuals):\n",
    "    high_protein_ad_revenue = 1\n",
    "    low_protein_ad_revenue = .25\n",
    "    \n",
    "    ad_revenue = 0\n",
    "    analysis_queue = []\n",
    "    active_recipes = []\n",
    "    i_data = 0\n",
    "    for _ in range(365):  # for one year\n",
    "        # 50-100 recipe submissions/day\n",
    "        num_submissions = np.random.randint(50, 100)\n",
    "        for i in range(num_submissions): # \n",
    "            if i_data < len(hp_predictions_and_actuals):\n",
    "                p, a = hp_predictions_and_actuals[i_data]\n",
    "                if p == 1:  # go to the front of the queue\n",
    "                    analysis_queue.insert(0, a)\n",
    "                    \n",
    "                else: # go to the back of the queue\n",
    "                    analysis_queue.append(a)\n",
    "                i_data += 1\n",
    "            \n",
    "        # can analyze only 25 recipes/day   \n",
    "        for __ in range(25):\n",
    "            if len(analysis_queue)==0:\n",
    "                break\n",
    "            acutal = analysis_queue.pop(0)\n",
    "            active_recipes.append(acutal)     \n",
    "        # run 500-1000 ads/day\n",
    "        num_ads_today = np.random.randint(500, 1000)\n",
    "        for a in random.choices(active_recipes, k=num_ads_today):\n",
    "            # a==1 if recipe is high protein\n",
    "            if a==1:\n",
    "                ad_revenue += high_protein_ad_revenue\n",
    "            else:\n",
    "                ad_revenue += low_protein_ad_revenue\n",
    "    \n",
    "    return ad_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Metric Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Lists for Final Comparison\n",
    "revenues = []\n",
    "thresholds = []\n",
    "accuracys = []\n",
    "times = []\n",
    "n_regressors = []\n",
    "std_err_revenues = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Random Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1 parameters standard error: \n",
      "chestnut               3.755319e+05\n",
      "sourdough              2.655035e+06\n",
      "rosemary               1.315083e-01\n",
      "game                   3.806022e-01\n",
      "semolina               7.875883e+05\n",
      "                           ...     \n",
      "macaroni_and_cheese    2.636263e+06\n",
      "kahl_a                 6.920765e+05\n",
      "graduation             3.691792e-01\n",
      "hamburger              1.805612e+06\n",
      "orange                 8.987992e-02\n",
      "Length: 100, dtype: float64\n",
      "\n",
      "Model 1 parameters standard error < 1: \n",
      "rosemary           1.315083e-01\n",
      "game               3.806022e-01\n",
      "duck               2.191133e-01\n",
      "noodle             2.195175e-01\n",
      "dairy              9.253052e-02\n",
      "easter             2.063452e-01\n",
      "low_cholesterol    2.146966e-01\n",
      "veal               1.854784e-01\n",
      "low_fat            1.370340e-01\n",
      "plum               3.651362e-01\n",
      "lemongrass         2.440959e-01\n",
      "eggplant           2.837167e-01\n",
      "rum                1.849943e-01\n",
      "hazelnut           3.622125e-01\n",
      "france             5.679224e-01\n",
      "grill              9.989724e-02\n",
      "broil              1.012878e-01\n",
      "cumin              3.232684e-01\n",
      "soy_sauce          1.211472e-01\n",
      "buffet             2.437987e-01\n",
      "scallop            1.707536e-01\n",
      "low_no_sugar       1.267518e-01\n",
      "anise              2.422613e-01\n",
      "lemon              7.310999e-02\n",
      "olive              1.034719e-01\n",
      "tangerine          3.901396e-01\n",
      "banana             4.780573e-01\n",
      "pecan              4.071616e-01\n",
      "fritter            1.711179e-09\n",
      "potluck            1.663763e-01\n",
      "peanut_free        3.107043e-02\n",
      "blue_cheese        2.561203e-01\n",
      "tea                2.627579e-01\n",
      "jalape_o           1.320947e-01\n",
      "mint               1.149369e-01\n",
      "white_wine         9.037857e-02\n",
      "cucumber           1.383313e-01\n",
      "halibut            2.949376e-01\n",
      "capers             1.792671e-01\n",
      "mango              1.849731e-01\n",
      "west_virginia      1.025218e-02\n",
      "mushroom           7.822910e-02\n",
      "sage               1.612134e-01\n",
      "christmas_eve      1.513489e-01\n",
      "cuba               1.713669e-02\n",
      "asparagus          1.975015e-01\n",
      "party              1.321744e-01\n",
      "butter             2.868265e-01\n",
      "graduation         3.691792e-01\n",
      "orange             8.987992e-02\n",
      "dtype: float64\n",
      "\n",
      "The Number of Selected Regressors = 100\n",
      "\n",
      "Model 1 Accuracy: 0.55 \n",
      "\n",
      "Model 1 Best threshold: 0.4 \n",
      "\n",
      "Model 1 Time: 9.48s\n",
      "\n",
      "Model 1 Revenue: $84259.25 \n",
      "\n",
      "Model 1 Revenue Standard Error: 0.91 \n"
     ]
    }
   ],
   "source": [
    "#Randomly select 100 regressors to build model\n",
    "random_columns = random.sample(list(data_balance.columns), 100)\n",
    "Train_data = pd.concat([data_balance[random_columns],data_balance.label], axis = 1)\n",
    "\n",
    "#Build a model formula with all regressors, excluding the intercept\n",
    "start1 = time.time()\n",
    "all_columns = \"+\".join(Train_data.columns.drop('label'))\n",
    "my_formula = \"label~\" + all_columns + '-1' \n",
    "\n",
    "#Using GLM and Binomial fit, we identify significant columns by p-values\n",
    "\n",
    "res_poly = glm(formula=my_formula, data=Train_data, family=sm.families.Binomial()).fit()\n",
    "\n",
    "signi_detail = res_poly.pvalues[res_poly.pvalues < 0.05]\n",
    "signi_columns = signi_detail.index\n",
    "\n",
    "random_columns = res_poly.params.index\n",
    "random_B = res_poly.params.values\n",
    "\n",
    "\"\"\" Select the GLM columns and their values to apply of predict() function to create an array, then we\n",
    "zip them with the actual class from the y (the label column). Here we will get an array of pairs to feed \n",
    "into the simulate() function. From there, we can calculate the Revenue of our Model #1 \"\"\"\n",
    "\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "# predict and evaluate the result\n",
    "threshold_candidate = np.arange(0.1,1,0.1)\n",
    "pre_revenue = -np.inf\n",
    "for threshold in threshold_candidate:\n",
    "    predictions = predict(x[random_columns], random_B, threshold)\n",
    "    actuals = np.array(y).copy()\n",
    "    hp_predictions_and_actuals = list(zip(predictions, actuals))\n",
    "    revenue = simulate(hp_predictions_and_actuals)\n",
    "    if revenue > pre_revenue:\n",
    "        pre_revenue = revenue\n",
    "        model1_best_threshold = np.round(threshold,1)\n",
    "        model1_predictions = predictions\n",
    "        final_hp_predictions_and_actuals = hp_predictions_and_actuals\n",
    "\n",
    "model1_revenue = np.round(pre_revenue,2)\n",
    "model1_accuracy = np.round(len(model1_predictions[model1_predictions==actuals])/len(model1_predictions),2)\n",
    "end1 = time.time()\n",
    "\n",
    "revenues_list = [simulate(final_hp_predictions_and_actuals) for _ in range(1000)]\n",
    "model1_revenue_std_error = std_revenue(revenues_list)\n",
    "\n",
    "model1_time = np.round(end1-start1,2)\n",
    "\n",
    "n_regressors.append(len(random_columns))\n",
    "revenues.append(model1_revenue)\n",
    "thresholds.append(model1_best_threshold)\n",
    "accuracys.append(model1_accuracy)\n",
    "times.append(model1_time)\n",
    "std_err_revenues.append(model1_revenue_std_error)\n",
    "\n",
    "print('\\nModel 1 parameters standard error: \\n{}'.format(res_poly.bse))\n",
    "print('\\nModel 1 parameters standard error < 1: \\n{}'.format(res_poly.bse[res_poly.bse<1]))\n",
    "print('\\nThe Number of Selected Regressors = {}'.format(len(random_columns)))\n",
    "print('\\nModel 1 Accuracy: {} '.format(model1_accuracy))\n",
    "print('\\nModel 1 Best threshold: {} '.format(model1_best_threshold))\n",
    "print('\\nModel 1 Time: {}s'.format(model1_time))\n",
    "print('\\nModel 1 Revenue: ${} '.format(model1_revenue))\n",
    "print('\\nModel 1 Revenue Standard Error: {} '.format(model1_revenue_std_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Significant Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 parameters standard error: \n",
      "advance_prep_required    3.063628e-01\n",
      "alabama                  7.056518e+00\n",
      "alaska                   1.008415e+01\n",
      "alcoholic                1.698797e+08\n",
      "almond                   3.904098e-01\n",
      "                             ...     \n",
      "cardamom                 5.246184e-01\n",
      "carrot                   1.198212e-01\n",
      "cashew                   2.518248e+07\n",
      "casserole_gratin         3.334335e+09\n",
      "cauliflower              6.898343e+08\n",
      "Length: 96, dtype: float64\n",
      "\n",
      "Model 2 parameters standard error < 1: \n",
      "advance_prep_required    0.306363\n",
      "almond                   0.390410\n",
      "anise                    0.319842\n",
      "anniversary              0.266817\n",
      "appetizer                0.099045\n",
      "apple                    0.206641\n",
      "apricot                  0.231898\n",
      "artichoke                0.272358\n",
      "arugula                  0.209511\n",
      "asparagus                0.284693\n",
      "australia                0.897377\n",
      "avocado                  0.430873\n",
      "back_to_school           0.233863\n",
      "backyard_bbq             0.112729\n",
      "bacon                    0.138825\n",
      "bake                     0.078568\n",
      "banana                   0.435140\n",
      "basil                    0.123113\n",
      "bass                     0.514311\n",
      "bean                     0.177380\n",
      "beef                     0.103226\n",
      "beef_shank               0.983916\n",
      "beer                     0.270308\n",
      "beet                     0.418751\n",
      "bell_pepper              0.126449\n",
      "berry                    0.231701\n",
      "blender                  0.217505\n",
      "blue_cheese              0.291174\n",
      "blueberry                0.268420\n",
      "boil                     0.217572\n",
      "bok_choy                 0.623353\n",
      "bon_app_tit              0.044326\n",
      "bourbon                  0.335303\n",
      "braise                   0.151882\n",
      "brandy                   0.186680\n",
      "brine                    0.841845\n",
      "broccoli                 0.382378\n",
      "broccoli_rabe            0.518294\n",
      "broil                    0.140805\n",
      "brunch                   0.167739\n",
      "brussel_sprout           0.501074\n",
      "buffet                   0.252422\n",
      "butternut_squash         0.541996\n",
      "cabbage                  0.218773\n",
      "california               0.216950\n",
      "cantaloupe               0.428931\n",
      "capers                   0.230781\n",
      "cardamom                 0.524618\n",
      "carrot                   0.119821\n",
      "dtype: float64\n",
      "\n",
      "The Number of Selected Regressors = 96\n",
      "\n",
      "Model 2 Accuracy: 0.6 \n",
      "\n",
      "Model 2 Best Threshold: 0.1 \n",
      "\n",
      "Model 2 Time: 165.11s\n",
      "\n",
      "Model 2 Revenue: $84129.0 \n",
      "\n",
      "Model 2 Revenue Standard Error: 0.94 \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Select the last 100 columns as Regressors and thee we refit with only the significant regressors as\n",
    "our model training \"\"\"\n",
    "\n",
    "x = data_balance.iloc[:, -101:-1]\n",
    "y = data_balance.iloc[:,-1]\n",
    "\n",
    "\"\"\" Define the log likelihood function and logistic regression fit \"\"\"\n",
    "\n",
    "def log_likelihood(X, y, B):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).flatten()\n",
    "    B = np.asarray(B).flatten()\n",
    "    pi = np.maximum(1e-9, np.minimum(1-1e-9, 1 / (1 + np.exp(-X@B))))\n",
    "    ll = (y*np.log(pi) + (1-y)*np.log(1-pi)).sum()\n",
    "    return ll\n",
    "\n",
    "def logistic_regression_fit(y, X):\n",
    "    num_regressors = X.shape[1]\n",
    "    res = so.minimize(lambda B: -log_likelihood(X, y, B), [0]*num_regressors)    \n",
    "    B = res.x\n",
    "    return pd.DataFrame(data=B[:,None].T, columns=X.columns).T\n",
    "\n",
    "#Calculate the Coefficients of our Beta Vector with logistic regresison fit function\n",
    "start2 = time.time()\n",
    "coefficients = logistic_regression_fit(y, x)\n",
    "B = coefficients.values.reshape(1,-1)[0]\n",
    "\n",
    "#Calculate t-score to verify if the coefficients are significantly different from zero\n",
    "t_scores = B/(np.std(x)/np.sqrt(len(data)))\n",
    "\n",
    "#Create List of the p-values from statsmodel \n",
    "p_values = scipy.stats.t.sf(np.abs(t_scores), df=len(data))*2\n",
    "\n",
    "#Use a significance level of Î±=.05 with and Confidence=.95 and append into list\n",
    "alpha = 0.05\n",
    "index = 0\n",
    "predictor_index = []\n",
    "for p in p_values:\n",
    "    if p<alpha:\n",
    "        predictor_index.append(index)\n",
    "    index+=1\n",
    "\n",
    "\"\"\" Apply the Logistic Regression Fit function to this new dataframe and our original label vector and \n",
    "identify the significant regressors to apply to simulate function \"\"\"\n",
    "\n",
    "signi_X = data.iloc[:,predictor_index]\n",
    "y = data.iloc[:,-1]\n",
    "coefficients_signi = logistic_regression_fit(y, signi_X)\n",
    "B_signi = coefficients_signi.values.reshape(1,-1)[0]\n",
    "Model2_SE_B = ((signi_X**2*np.exp(B_signi*signi_X)/((1+np.exp(B_signi*signi_X))**2)).sum())**(-1/2)\n",
    "\n",
    "\"\"\" Reapply our GLM function to new reduced data, acquire an array and zip to our original y vector\n",
    "then apply simulate function to obtain our new revenue estimate\"\"\"\n",
    "\n",
    "# predict and evaluate the result\n",
    "threshold_candidate = np.arange(0.1,1,0.1)\n",
    "pre_revenue = -np.inf\n",
    "for threshold in threshold_candidate:\n",
    "    predictions = predict(signi_X, B_signi, threshold)\n",
    "    actuals = np.array(y).copy()\n",
    "    hp_predictions_and_actuals = list(zip(predictions, actuals))\n",
    "    revenue = simulate(hp_predictions_and_actuals)\n",
    "    if revenue > pre_revenue:\n",
    "        pre_revenue = revenue\n",
    "        model2_best_threshold = np.round(threshold,1)\n",
    "        model2_predictions = predictions\n",
    "        final_hp_predictions_and_actuals = hp_predictions_and_actuals\n",
    "\n",
    "end2 = time.time()\n",
    "\n",
    "revenues_list = [simulate(final_hp_predictions_and_actuals) for _ in range(1000)]\n",
    "model2_revenue_std_error = std_revenue(revenues_list)\n",
    "\n",
    "model2_time = np.round(end2-start2,2)\n",
    "        \n",
    "model2_revenue = np.round(pre_revenue,2)\n",
    "model2_accuracy = np.round(len(model2_predictions[model2_predictions==actuals])/len(model2_predictions),2)\n",
    "\n",
    "n_regressors.append(len(predictor_index))\n",
    "revenues.append(model2_revenue)\n",
    "thresholds.append(model2_best_threshold)\n",
    "accuracys.append(model2_accuracy)\n",
    "times.append(model2_time)\n",
    "std_err_revenues.append(model2_revenue_std_error)\n",
    "\n",
    "print('\\nModel 2 parameters standard error: \\n{}'.format(Model2_SE_B))\n",
    "print('\\nModel 2 parameters standard error < 1: \\n{}'.format(Model2_SE_B[Model2_SE_B<1]))\n",
    "print('\\nThe Number of Selected Regressors = {}'.format(len(predictor_index)))\n",
    "print('\\nModel 2 Accuracy: {} '.format(model2_accuracy))\n",
    "print('\\nModel 2 Best Threshold: {} '.format(model2_best_threshold))\n",
    "print('\\nModel 2 Time: {}s'.format(model2_time))\n",
    "print('\\nModel 2 Revenue: ${} '.format(model2_revenue))\n",
    "print('\\nModel 2 Revenue Standard Error: {} '.format(model2_revenue_std_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: High Correlation Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 3 parameters standard error: \n",
      "alcoholic            2.040975e+16\n",
      "almond               1.785671e-01\n",
      "apple                1.364408e-01\n",
      "bake                 3.986198e-02\n",
      "bass                 2.081766e-01\n",
      "bread                7.620423e+05\n",
      "breakfast            1.123380e+02\n",
      "brunch               9.871160e-02\n",
      "cake                 5.782707e+08\n",
      "cheese               1.358020e-01\n",
      "chicken              5.187457e-02\n",
      "chill                8.647408e-02\n",
      "chocolate            9.338655e-02\n",
      "clam                 1.747684e-01\n",
      "cocktail_party       8.194631e-02\n",
      "condiment_spread     1.214849e-01\n",
      "dairy                6.749000e-02\n",
      "dessert              1.175879e+06\n",
      "dinner               3.522416e-02\n",
      "drink                1.646854e+06\n",
      "egg                  6.805343e-02\n",
      "fish                 6.476502e-02\n",
      "fruit                5.613960e-02\n",
      "grill_barbecue       5.378000e-02\n",
      "halibut              1.927060e-01\n",
      "kid_friendly         5.848591e-02\n",
      "kidney_friendly      5.451076e-02\n",
      "kosher               3.117595e-02\n",
      "lobster              3.096565e-01\n",
      "marinate             6.819353e-02\n",
      "milk_cream           5.858703e-02\n",
      "mixer                7.479339e+06\n",
      "no_cook              7.925979e-02\n",
      "nut                  2.239008e-01\n",
      "parmesan             1.078882e-01\n",
      "party                1.157654e-01\n",
      "pasta                1.617508e-01\n",
      "peanut_free          3.021339e-02\n",
      "pescatarian          3.359065e-02\n",
      "pork_tenderloin      1.878444e-01\n",
      "potato               9.177703e-02\n",
      "poultry              5.739494e-02\n",
      "roast                3.980936e-02\n",
      "salad                7.705108e-02\n",
      "sauce                9.688889e-02\n",
      "seafood              7.923402e-02\n",
      "shellfish            7.778865e-02\n",
      "shrimp               7.632214e-02\n",
      "side                 6.146498e-02\n",
      "snapper              1.757559e-01\n",
      "soup_stew            4.881085e-02\n",
      "soy_free             2.500064e-02\n",
      "thanksgiving         3.946838e-02\n",
      "tree_nut_free        2.866595e-02\n",
      "vegan                3.936578e+11\n",
      "vegetarian           1.161204e-01\n",
      "wheat_gluten_free    3.218813e-02\n",
      "white_wine           7.425377e-02\n",
      "turkey               1.138017e-01\n",
      "dtype: float64\n",
      "\n",
      "Model 3 parameters standard error < 1: \n",
      "almond               0.178567\n",
      "apple                0.136441\n",
      "bake                 0.039862\n",
      "bass                 0.208177\n",
      "brunch               0.098712\n",
      "cheese               0.135802\n",
      "chicken              0.051875\n",
      "chill                0.086474\n",
      "chocolate            0.093387\n",
      "clam                 0.174768\n",
      "cocktail_party       0.081946\n",
      "condiment_spread     0.121485\n",
      "dairy                0.067490\n",
      "dinner               0.035224\n",
      "egg                  0.068053\n",
      "fish                 0.064765\n",
      "fruit                0.056140\n",
      "grill_barbecue       0.053780\n",
      "halibut              0.192706\n",
      "kid_friendly         0.058486\n",
      "kidney_friendly      0.054511\n",
      "kosher               0.031176\n",
      "lobster              0.309656\n",
      "marinate             0.068194\n",
      "milk_cream           0.058587\n",
      "no_cook              0.079260\n",
      "nut                  0.223901\n",
      "parmesan             0.107888\n",
      "party                0.115765\n",
      "pasta                0.161751\n",
      "peanut_free          0.030213\n",
      "pescatarian          0.033591\n",
      "pork_tenderloin      0.187844\n",
      "potato               0.091777\n",
      "poultry              0.057395\n",
      "roast                0.039809\n",
      "salad                0.077051\n",
      "sauce                0.096889\n",
      "seafood              0.079234\n",
      "shellfish            0.077789\n",
      "shrimp               0.076322\n",
      "side                 0.061465\n",
      "snapper              0.175756\n",
      "soup_stew            0.048811\n",
      "soy_free             0.025001\n",
      "thanksgiving         0.039468\n",
      "tree_nut_free        0.028666\n",
      "vegetarian           0.116120\n",
      "wheat_gluten_free    0.032188\n",
      "white_wine           0.074254\n",
      "turkey               0.113802\n",
      "dtype: float64\n",
      "\n",
      "The Number of Selected Regressors = 59\n",
      "\n",
      "Model 3 Accuracy: 0.71 \n",
      "\n",
      "Model 3 Best Threshold: 0.2 \n",
      "\n",
      "Model 3 Time: 42.63s\n",
      "\n",
      "Model 3 Revenue: $91721.25 \n",
      "\n",
      "Model 3 Revenue Standard Error: 0.95 \n"
     ]
    }
   ],
   "source": [
    "#Use all columns as regressors to find the high correlation \n",
    "x = data_balance.iloc[:, :-1]\n",
    "y = data_balance.iloc[:,-1]\n",
    "\n",
    "#Identify features with correlation to label greater than 0.1\n",
    "high_corr_columns = [column for column in x.columns if abs(x[column].corr(y)) > 0.1]\n",
    "\n",
    "\"\"\" Reapply our GLM function to columns with high correlation, then we acquire an array \n",
    "and zip to our original y vector, finally: then apply simulate function to obtain our \n",
    "new revenue estimate\"\"\"\n",
    "\n",
    "start3 = time.time()\n",
    "coefficients_high_corr = logistic_regression_fit(y, x[high_corr_columns])\n",
    "B_high_corr = coefficients_high_corr.values.reshape(1,-1)[0]\n",
    "Model3_SE_B = ((x[high_corr_columns]**2*np.exp(B_high_corr*x[high_corr_columns])/((1+np.exp(B_high_corr*x[high_corr_columns]))**2)).sum())**(-1/2)\n",
    "\n",
    "\n",
    "# predict and evaluate the result\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "threshold_candidate = np.arange(0.1,1,0.1)\n",
    "pre_revenue = -np.inf\n",
    "for threshold in threshold_candidate:\n",
    "    predictions = predict(x[high_corr_columns], B_high_corr, threshold)\n",
    "    actuals = np.array(y).copy()\n",
    "    hp_predictions_and_actuals = list(zip(predictions, actuals))\n",
    "    revenue = simulate(hp_predictions_and_actuals)\n",
    "    if revenue > pre_revenue:\n",
    "        pre_revenue = revenue\n",
    "        model3_best_threshold = np.round(threshold,1)\n",
    "        model3_predictions = predictions\n",
    "        final_hp_predictions_and_actuals = hp_predictions_and_actuals\n",
    "        \n",
    "end3 = time.time()\n",
    "model3_time = np.round(end3-start3,2)\n",
    "        \n",
    "revenues_list = [simulate(final_hp_predictions_and_actuals) for _ in range(1000)]\n",
    "model3_revenue_std_error = std_revenue(revenues_list)\n",
    "\n",
    "model3_revenue = np.round(pre_revenue,2)\n",
    "model3_accuracy = np.round(len(model3_predictions[model3_predictions==actuals])/len(model3_predictions),2)\n",
    "\n",
    "n_regressors.append(len(high_corr_columns))\n",
    "revenues.append(model3_revenue)\n",
    "thresholds.append(model3_best_threshold)\n",
    "accuracys.append(model3_accuracy)\n",
    "times.append(model3_time)\n",
    "std_err_revenues.append(model3_revenue_std_error)\n",
    "\n",
    "print('\\nModel 3 parameters standard error: \\n{}'.format(Model3_SE_B))\n",
    "print('\\nModel 3 parameters standard error < 1: \\n{}'.format(Model3_SE_B[Model3_SE_B<1]))\n",
    "print('\\nThe Number of Selected Regressors = {}'.format(len(high_corr_columns)))\n",
    "print('\\nModel 3 Accuracy: {} '.format(model3_accuracy))\n",
    "print('\\nModel 3 Best Threshold: {} '.format(model3_best_threshold))\n",
    "print('\\nModel 3 Time: {}s'.format(model3_time))\n",
    "print('\\nModel 3 Revenue: ${} '.format(model3_revenue))\n",
    "print('\\nModel 3 Revenue Standard Error: {} '.format(model3_revenue_std_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Chi Square Test Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 4 parameters standard error: \n",
      "vegetarian               0.143364\n",
      "dessert                 35.207110\n",
      "bake                     0.050376\n",
      "kosher                   0.034923\n",
      "side                     0.080219\n",
      "turkey                   0.198095\n",
      "pescatarian              0.038197\n",
      "kidney_friendly          0.056313\n",
      "milk_cream               0.069240\n",
      "vegan                 4769.719509\n",
      "fish                     0.095651\n",
      "egg                      0.084514\n",
      "soy_free                 0.030424\n",
      "fruit                    0.061755\n",
      "dairy                    0.076782\n",
      "cheese                   0.122211\n",
      "peanut_free              0.032949\n",
      "kid_friendly             0.077585\n",
      "salad                    0.080664\n",
      "vegetable                0.065755\n",
      "chill                    0.093684\n",
      "winter                   0.052931\n",
      "drink                 1103.743689\n",
      "potato                   0.105778\n",
      "condiment_spread         0.209354\n",
      "nut                      0.148487\n",
      "no_cook                  0.093142\n",
      "sauce                    0.133659\n",
      "roast                    0.077844\n",
      "chocolate                0.128575\n",
      "wheat_gluten_free        0.039073\n",
      "cake                    73.548837\n",
      "cocktail_party           0.100895\n",
      "pasta                    0.160883\n",
      "food_processor           0.091835\n",
      "brunch                   0.097652\n",
      "thanksgiving             0.070470\n",
      "alcoholic            22897.454918\n",
      "leafy_green              0.104631\n",
      "mixer                   33.452803\n",
      "high_fiber               0.099828\n",
      "breakfast             1109.452889\n",
      "bon_app_tit              0.033589\n",
      "party                    0.109336\n",
      "tree_nut_free            0.032622\n",
      "summer                   0.045072\n",
      "almond                   0.254351\n",
      "apple                    0.131352\n",
      "parmesan                 0.141746\n",
      "lunch                    0.082316\n",
      "dtype: float64\n",
      "\n",
      "Model 4 parameters standard error < 1: \n",
      "vegetarian           0.143364\n",
      "bake                 0.050376\n",
      "kosher               0.034923\n",
      "side                 0.080219\n",
      "turkey               0.198095\n",
      "pescatarian          0.038197\n",
      "kidney_friendly      0.056313\n",
      "milk_cream           0.069240\n",
      "fish                 0.095651\n",
      "egg                  0.084514\n",
      "soy_free             0.030424\n",
      "fruit                0.061755\n",
      "dairy                0.076782\n",
      "cheese               0.122211\n",
      "peanut_free          0.032949\n",
      "kid_friendly         0.077585\n",
      "salad                0.080664\n",
      "vegetable            0.065755\n",
      "chill                0.093684\n",
      "winter               0.052931\n",
      "potato               0.105778\n",
      "condiment_spread     0.209354\n",
      "nut                  0.148487\n",
      "no_cook              0.093142\n",
      "sauce                0.133659\n",
      "roast                0.077844\n",
      "chocolate            0.128575\n",
      "wheat_gluten_free    0.039073\n",
      "cocktail_party       0.100895\n",
      "pasta                0.160883\n",
      "food_processor       0.091835\n",
      "brunch               0.097652\n",
      "thanksgiving         0.070470\n",
      "leafy_green          0.104631\n",
      "high_fiber           0.099828\n",
      "bon_app_tit          0.033589\n",
      "party                0.109336\n",
      "tree_nut_free        0.032622\n",
      "summer               0.045072\n",
      "almond               0.254351\n",
      "apple                0.131352\n",
      "parmesan             0.141746\n",
      "lunch                0.082316\n",
      "dtype: float64\n",
      "\n",
      "The Number of Selected Regressors = 50\n",
      "\n",
      "Model 4 Accuracy: 0.8 \n",
      "\n",
      "Model 4 Best Threshold: 0.1 \n",
      "\n",
      "Model 4 Time: 25.34s\n",
      "\n",
      "Model 4 Revenue: $88030.5 \n",
      "\n",
      "Model 4 Revenue Standard Error: 0.89 \n"
     ]
    }
   ],
   "source": [
    "#Select our X explanatory variables and response variable\n",
    "x = data_balance.iloc[:, :-1]\n",
    "y = data_balance.iloc[:,-1]\n",
    "\n",
    "#Use SelectKBest function to fit\n",
    "start4 = time.time()\n",
    "bestfeatures = SelectKBest(score_func=chi2)\n",
    "\n",
    "# Convert to categorical data by converting data to integers\n",
    "x = x.astype(int)\n",
    "\n",
    "fit = bestfeatures.fit(x,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['element','Score']  #naming the dataframe columns\n",
    "featureScores = featureScores.sort_values(by='Score', ascending=False) # set the order from high to low\n",
    "\n",
    "#Select the most important 50 columns based on calculated Chi-Square test\n",
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "selected_columns = featureScores[:50].element.values\n",
    "coefficients_selected = logistic_regression_fit(y, x[selected_columns])\n",
    "B_selected = coefficients_selected.values.reshape(1,-1)[0]\n",
    "Model4_SE_B = ((x[selected_columns]**2*np.exp(B_selected*x[selected_columns])/((1+np.exp(B_selected*x[selected_columns]))**2)).sum())**(-1/2)\n",
    "\n",
    "\n",
    "threshold_candidate = np.arange(0.1,1,0.1)\n",
    "pre_revenue = -np.inf\n",
    "for threshold in threshold_candidate:\n",
    "    predictions = predict(x[selected_columns], B_selected, threshold)\n",
    "    actuals = np.array(y).copy()\n",
    "    hp_predictions_and_actuals = list(zip(predictions, actuals))\n",
    "    revenue = simulate(hp_predictions_and_actuals)\n",
    "    if revenue > pre_revenue:\n",
    "        pre_revenue = revenue\n",
    "        model4_best_threshold = np.round(threshold,1)\n",
    "        model4_predictions = predictions\n",
    "        final_hp_predictions_and_actuals = hp_predictions_and_actuals\n",
    "        \n",
    "end4 = time.time()\n",
    "model4_time = np.round(end4-start4,2)\n",
    "        \n",
    "revenues_list = [simulate(final_hp_predictions_and_actuals) for _ in range(1000)]\n",
    "model4_revenue_std_error = std_revenue(revenues_list)    \n",
    "\n",
    "model4_revenue = np.round(pre_revenue,2)\n",
    "model4_accuracy = np.round(len(model4_predictions[model4_predictions==actuals])/len(model4_predictions),2)\n",
    "\n",
    "n_regressors.append(len(selected_columns))\n",
    "revenues.append(model4_revenue)\n",
    "thresholds.append(model4_best_threshold)\n",
    "accuracys.append(model4_accuracy)\n",
    "times.append(model4_time)\n",
    "std_err_revenues.append(model4_revenue_std_error)\n",
    "\n",
    "print('\\nModel 4 parameters standard error: \\n{}'.format(Model4_SE_B))\n",
    "print('\\nModel 4 parameters standard error < 1: \\n{}'.format(Model4_SE_B[Model4_SE_B<1]))\n",
    "print('\\nThe Number of Selected Regressors = {}'.format(len(selected_columns)))\n",
    "print('\\nModel 4 Accuracy: {} '.format(model4_accuracy))\n",
    "print('\\nModel 4 Best Threshold: {} '.format(model4_best_threshold))\n",
    "print('\\nModel 4 Time: {}s'.format(model4_time))\n",
    "print('\\nModel 4 Revenue: ${} '.format(model4_revenue))\n",
    "print('\\nModel 4 Revenue Standard Error: {} '.format(model4_revenue_std_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Bootstrap & Logit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 5 parameters standard error: \n",
      "advance_prep_required    0.162691\n",
      "alabama                  2.000004\n",
      "alaska                   2.005975\n",
      "alcoholic                0.158021\n",
      "almond                   0.116390\n",
      "                           ...   \n",
      "cookbooks                1.414215\n",
      "leftovers                1.561801\n",
      "snack                    0.541421\n",
      "snack_week               0.633959\n",
      "turkey                   0.153052\n",
      "Length: 669, dtype: float64\n",
      "\n",
      "Model 5 parameters standard error < 1: \n",
      "advance_prep_required    0.162691\n",
      "alcoholic                0.158021\n",
      "almond                   0.116390\n",
      "amaretto                 0.534743\n",
      "anchovy                  0.534566\n",
      "                           ...   \n",
      "yogurt                   0.102197\n",
      "zucchini                 0.138798\n",
      "snack                    0.541421\n",
      "snack_week               0.633959\n",
      "turkey                   0.153052\n",
      "Length: 516, dtype: float64\n",
      "\n",
      "The Number of Selected Regressors = 669\n",
      "\n",
      "Model 5 Accuracy: 0.75 \n",
      "\n",
      "Model 5 Best Threshold: 0.1 \n",
      "\n",
      "Model 5 Time: 9.77s\n",
      "\n",
      "Model 5 Revenue: $91066.25 \n",
      "\n",
      "Model 5 Revenue Standard Error: 0.96 \n"
     ]
    }
   ],
   "source": [
    "\"\"\" This model we will bootstrap to create an equal number of high protein and low protein labels. First \n",
    "we pick out high protein rows\"\"\"\n",
    "\n",
    "num_hight = data[data['label']==1]\n",
    "num_low = data[data['label']==0]\n",
    "high_random = []\n",
    "\n",
    "start5 = time.time()\n",
    "for i in range(len(num_low)-len(num_hight)):\n",
    "    randon_line = num_hight.iloc[np.random.randint(len(num_hight)),:]\n",
    "    high_random.append(randon_line)\n",
    "bootstrap_data = data.append(high_random)\n",
    "\n",
    "X = bootstrap_data.iloc[:,:-1]\n",
    "y = bootstrap_data.iloc[:,-1]\n",
    "X_p = data.iloc[:,:-1]\n",
    "y_orig = data.iloc[:,-1]\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "B = clf.coef_\n",
    "A = clf.intercept_\n",
    "B = B.flatten()\n",
    "model5_prediction = (A+X_p@B)\n",
    "\n",
    "threshold_candidate = np.arange(0.1,1,0.1)\n",
    "pre_revenue = -np.inf\n",
    "for threshold in threshold_candidate:\n",
    "    predictions = 1 / (1 + np.exp(-model5_prediction))\n",
    "    model5_prediction_sigmoid = np.where(predictions > threshold, 1, 0)\n",
    "    predictions = model5_prediction_sigmoid\n",
    "    actuals = np.array(y_orig).copy()\n",
    "    hp_predictions_and_actuals = list(zip(predictions, actuals))\n",
    "    revenue = simulate(hp_predictions_and_actuals)\n",
    "    if revenue > pre_revenue:\n",
    "        pre_revenue = revenue\n",
    "        model5_best_threshold = np.round(threshold,1)\n",
    "        model5_predictions = predictions\n",
    "        final_hp_predictions_and_actuals = hp_predictions_and_actuals\n",
    "        \n",
    "hp_predictions_and_actuals = list(zip(model5_predictions, y_orig))       \n",
    "end5 = time.time()\n",
    "        \n",
    "#time\n",
    "model5_time = np.round(end5-start5,2)\n",
    "\n",
    "revenues_list = [simulate(final_hp_predictions_and_actuals) for _ in range(1000)]\n",
    "model5_revenue_std_error = std_revenue(revenues_list) \n",
    "\n",
    "#revenue\n",
    "model5_revenue = simulate(hp_predictions_and_actuals)\n",
    "#number of regressors\n",
    "model5_N_Regressors = len(X.columns)\n",
    "#accuracy\n",
    "model5_predictions = [int(i) for i in model5_predictions]\n",
    "model5_predictions = np.array(model5_predictions)\n",
    "y_actual = np.array(y_orig)\n",
    "model5_accracy = np.round((len(model5_predictions[model5_predictions == y_actual])/len(model5_predictions)),2)\n",
    "#standard error\n",
    "Model5_SE_B = ((X**2*np.exp(B*X)/((1+np.exp(B*X))**2)).sum())**(-1/2)\n",
    "\n",
    "n_regressors.append(model5_N_Regressors)\n",
    "revenues.append(model5_revenue)\n",
    "thresholds.append(model5_best_threshold)\n",
    "accuracys.append(model5_accracy)\n",
    "times.append(model5_time)\n",
    "std_err_revenues.append(model5_revenue_std_error)\n",
    "\n",
    "\n",
    "print('\\nModel 5 parameters standard error: \\n{}'.format(Model5_SE_B))\n",
    "print('\\nModel 5 parameters standard error < 1: \\n{}'.format(Model5_SE_B[Model5_SE_B<1]))\n",
    "print('\\nThe Number of Selected Regressors = {}'.format(model5_N_Regressors))\n",
    "print('\\nModel 5 Accuracy: {} '.format(model5_accracy))\n",
    "print('\\nModel 5 Best Threshold: {} '.format(model5_best_threshold))\n",
    "print('\\nModel 5 Time: {}s'.format(model5_time))\n",
    "print('\\nModel 5 Revenue: ${} '.format(model5_revenue))\n",
    "print('\\nModel 5 Revenue Standard Error: {} '.format(model5_revenue_std_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Revenue Outcome and Model Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 has Revenue generation = $84259.25\n",
      "Model 2 has Revenue generation = $84129.0\n",
      "Model 3 has Revenue generation = $91721.25\n",
      "Model 4 has Revenue generation = $88030.5\n",
      "Model 5 has Revenue generation = $91066.25\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 has Revenue generation = ${}'.format(model1_revenue))\n",
    "print('Model 2 has Revenue generation = ${}'.format(model2_revenue))\n",
    "print('Model 3 has Revenue generation = ${}'.format(model3_revenue))\n",
    "print('Model 4 has Revenue generation = ${}'.format(model4_revenue))\n",
    "print('Model 5 has Revenue generation = ${}'.format(model5_revenue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------+----------+------------------------+----------------+----------+--------+\n",
      "|             Model              | N_Regressors | Revenue  | Standard Error Revenue | Best Threshold | Accuracy |  Time  |\n",
      "+--------------------------------+--------------+----------+------------------------+----------------+----------+--------+\n",
      "|        Random Selection        |     100      | 84259.25 |          0.91          |      0.4       |   0.55   |  9.48  |\n",
      "| P-value Significant Regressors |      96      | 84129.0  |          0.94          |      0.1       |   0.6    | 165.11 |\n",
      "|    High Correlation Columns    |      59      | 91721.25 |          0.95          |      0.2       |   0.71   | 42.63  |\n",
      "|      Chi-Square Selection      |      50      | 88030.5  |          0.89          |      0.1       |   0.8    | 25.34  |\n",
      "|  Bootstrap & Logit Regression  |     669      | 91066.25 |          0.96          |      0.1       |   0.75   |  9.77  |\n",
      "+--------------------------------+--------------+----------+------------------------+----------------+----------+--------+\n"
     ]
    }
   ],
   "source": [
    "columns = ['Model', 'N_Regressors', 'Revenue', 'Standard Error Revenue', 'Best Threshold', 'Accuracy', 'Time']\n",
    "models = ['Random Selection','P-value Significant Regressors','High Correlation Columns',\n",
    "          'Chi-Square Selection','Bootstrap & Logit Regression']\n",
    "myTable = PrettyTable()\n",
    "\n",
    "# Add Columns\n",
    "myTable.add_column(columns[0], models)\n",
    "myTable.add_column(columns[1], n_regressors)\n",
    "myTable.add_column(columns[2], revenues)\n",
    "myTable.add_column(columns[3], std_err_revenues)\n",
    "myTable.add_column(columns[4], thresholds)\n",
    "myTable.add_column(columns[5], accuracys)\n",
    "myTable.add_column(columns[6], times)\n",
    "\n",
    "print(myTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Predict # of High protein is 5068, Low protein is 5525\n",
      "Model 2 Predict # of High protein is 4397, Low protein is 6196\n",
      "Model 3 Predict # of High protein is 3557, Low protein is 7036\n",
      "Model 4 Predict # of High protein is 2411, Low protein is 8182\n",
      "Model 5 Predict # of High protein is 3138, Low protein is 7455\n",
      "Original DataFrame: High protein = 532, Low protein = 10061\n"
     ]
    }
   ],
   "source": [
    "predictions_all_models = [model1_predictions,model2_predictions,model3_predictions,model4_predictions]\n",
    "print('Model 1 Predict # of High protein is {}, Low protein is {}'.format(len(model1_predictions[model1_predictions==1]), len(model1_predictions[model1_predictions==0])))\n",
    "print('Model 2 Predict # of High protein is {}, Low protein is {}'.format(len(model2_predictions[model2_predictions==1]), len(model2_predictions[model2_predictions==0])))\n",
    "print('Model 3 Predict # of High protein is {}, Low protein is {}'.format(len(model3_predictions[model3_predictions==1]), len(model3_predictions[model3_predictions==0])))\n",
    "print('Model 4 Predict # of High protein is {}, Low protein is {}'.format(len(model4_predictions[model4_predictions==1]), len(model4_predictions[model4_predictions==0])))\n",
    "print(f'Model 5 Predict # of High protein is {len(model5_predictions[model5_predictions == 1])}, Low protein is {len(model5_predictions[model5_predictions == 0])}')\n",
    "print('Original DataFrame: High protein = {}, Low protein = {}'.format(len(data[data.label==1]), len(data[data.label==0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict function for output samples testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def simulate(hp_predictions_and_actuals):\n",
    "    high_protein_ad_revenue = 1\n",
    "    low_protein_ad_revenue = .25\n",
    "    \n",
    "    ad_revenue = 0\n",
    "    analysis_queue = []\n",
    "    active_recipes = []\n",
    "    i_data = 0\n",
    "    for _ in range(365):  # for one year\n",
    "        # 50-100 recipe submissions/day\n",
    "        num_submissions = np.random.randint(50, 100)\n",
    "        for i in range(num_submissions): # \n",
    "            if i_data < len(hp_predictions_and_actuals):\n",
    "                p, a = hp_predictions_and_actuals[i_data]\n",
    "                if p == 1:  # go to the front of the queue\n",
    "                    analysis_queue.insert(0, a)\n",
    "                    \n",
    "                else: # go to the back of the queue\n",
    "                    analysis_queue.append(a)\n",
    "                i_data += 1\n",
    "            \n",
    "        # can analyze only 25 recipes/day   \n",
    "        for __ in range(25):\n",
    "            if len(analysis_queue)==0:\n",
    "                break\n",
    "            acutal = analysis_queue.pop(0)\n",
    "            active_recipes.append(acutal)     \n",
    "        # run 500-1000 ads/day\n",
    "        num_ads_today = np.random.randint(500, 1000)\n",
    "        for a in random.choices(active_recipes, k=num_ads_today):\n",
    "            # a==1 if recipe is high protein\n",
    "            if a==1:\n",
    "                ad_revenue += high_protein_ad_revenue\n",
    "            else:\n",
    "                ad_revenue += low_protein_ad_revenue\n",
    "    \n",
    "    return ad_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def predict(df):\n",
    "    df['label']=df['protein']/df['calories']\n",
    "    df['label'] = np.where(df['label']>0.1, 1, 0)\n",
    "    data = df_recipe.iloc[:,3:].copy()\n",
    "    num_hight = data[data['label']==1]\n",
    "    num_low = data[data['label']==0]\n",
    "    high_random = []\n",
    "    \n",
    "    for i in range(len(num_low)-len(num_hight)):\n",
    "        randon_line = num_hight.iloc[np.random.randint(len(num_hight)),:]\n",
    "        high_random.append(randon_line)\n",
    "    bootstrap_data = data.append(high_random)\n",
    "\n",
    "    X = bootstrap_data.iloc[:,:-1]\n",
    "    y = bootstrap_data.iloc[:,-1]\n",
    "    X_orig = data.iloc[:,:-1]\n",
    "    clf = LogisticRegression(random_state=0,solver='lbfgs', max_iter=1000).fit(X, y)\n",
    "\n",
    "    B = clf.coef_\n",
    "    B = B.flatten()\n",
    "    A = clf.intercept_\n",
    "    \n",
    "    model5_prediction = (A+X_orig@B)\n",
    "    # using sigmoid tranform to logistic\n",
    "    predictions = 1 / (1 + np.exp(-model5_prediction))\n",
    "    threshold = 0.4\n",
    "    predictions = np.where(predictions > threshold, 1, 0)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipe = pd.read_csv('final_data_set.csv',index_col=0)\n",
    "predict(df_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
